---
title: "Exploring Seed Data from League of Legends"
author: "Branden Carrier"
date: "`r format(Sys.time(), '%B %d, %Y')`"
abstract: "Give a non-English speaker a pair of headsets and play two recordings made in English&mdash;one, a sports broadcast, and the other, a League of Legends (LoL) broadcast. The person will not likely be able to discern that the LoL broadcast isn't reporting a sports match. LoL and sports, with the physical aspect removed, have much in common: both have strong fanbases, both have rigorous and, perhaps surprisingly, lucrative competitions, and both inspire their fans to uncover the underlying mechanisms that lead to victory and to better gameplay. Such is the object of this analysis."
output:
  html_document: default
  pdf_document:
    latex_engine: lualatex
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=FALSE)
library(alluvial)
library(boot)
library(data.table)
library(dplyr)
library(ggplot2)
library(grid)
library(gridExtra)
library(png)
library(tidyr)

setwd('Q:\\Program Files\\Programming Applications\\Projects\\Udacity\\Data Analysis Nanodegree\\P4\\')
```

# Death Location Patterns

```{python death_location_import}
import matplotlib.pyplot as plt
import pandas as pd

P4_PATH = 'Q:\\Program Files\\Programming Applications\\Projects\\Udacity\\Data Analysis Nanodegree\\P4\\'

death_location = pd.read_csv(P4_PATH + 'datasets-csv\\death_location.csv')
```

This dataset consists of 63,755 observations of death and 3 variables detailing the death occurence's position and time. 

```{python death_location_frequency, include=FALSE}
import matplotlib.pyplot as plt
import pandas as pd

P4_PATH = 'Q:\\Program Files\\Programming Applications\\Projects\\Udacity\\Data Analysis Nanodegree\\P4\\'

death_location = pd.read_csv(P4_PATH + 'datasets-csv\\death_location.csv')

fig, axs = plt.subplots(ncols=2, figsize=(17, 7))

ax = axs[0]
hb = ax.hexbin(x=death_location['x'], y=death_location['y'], gridsize=125, cmap='inferno')
ax.axis('off')
ax.set_title('Death Location Frequency')
cb = fig.colorbar(hb, ax=ax)
cb.set_label('Frequency')

ax1 = axs[1]
im = plt.imread(P4_PATH + 'misc\\summoners_rift.png')
implot = plt.imshow(im, origin='upper')
ax1.axis('off')

plt.tight_layout()

plt.savefig(P4_PATH + 'misc\\death_location_heatmap.png', bbox_inches='tight')
```

<center>![Death Location Frequency](misc\\death_location_heatmap.png)</center>

As you might expect, the majority of deaths occured within the lanes, and in partucilar, in the middle of the map for each lane. The middle lane appears to be the most active lane, while the top, the least. 

There is one noticeable and somewhat unexpected aspect.

<center>![Ganking circled](misc\\heatmap-circled.png)</center>

Take a look at these hotspots. The activity in these locations is rather high, especially as jungle locations. Perhaps these are the most popular (or maybe most successful) ganking locations.

Now, let's see how death occurences change with respect to time. In the image below, death location frequencies are depicted over four intervals, each representing a quarter of the interval $(0, \text{max}(t))$, where $\text{max}(t)$ represents the largest timestamp value in the dataset. Even if, for one game, the end time occurs in the third interval, while, for another, in the fourth, this partitioning should give us a rough idea of what's going on.

```{python death_location_time, include=FALSE}
import matplotlib.pyplot as plt
import pandas as pd

P4_PATH = 'Q:\\Program Files\\Programming Applications\\Projects\\Udacity\\Data Analysis Nanodegree\\P4\\'

death_location = pd.read_csv(P4_PATH + 'datasets-csv\\death_location.csv')

fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(6, 17))
intervals = death_location['timestamp'].quantile([i/4 for i in range(1, 5)]).values

ax = axs[0]
hb = ax.hexbin(x=death_location.loc[death_location['timestamp'] <= intervals[0], 'x'],
               y=death_location.loc[death_location['timestamp'] <= intervals[0], 'y'],
               gridsize=125, cmap='inferno')
ax.axis('off')
ax.set_title('Death Location Frequency Over Time: Interval 1')
cb = fig.colorbar(hb, ax=ax)
cb.set_label('Frequency')

ax = axs[1]
hb = ax.hexbin(x=death_location.loc[(death_location['timestamp'] >= intervals[0]) &
                                    (death_location['timestamp'] <= intervals[1]), 'x'],
               y=death_location.loc[(death_location['timestamp'] >= intervals[0]) &
                                    (death_location['timestamp'] <= intervals[1]), 'y'],
               gridsize=125, cmap='inferno')
ax.axis('off')
ax.set_title('Interval 2')
cb = fig.colorbar(hb, ax=ax, ticks=range(0, 16))
cb.set_label('Frequency')
range(0, 16)
ax = axs[2]
hb = ax.hexbin(x=death_location.loc[(death_location['timestamp'] >= intervals[1]) &
                                    (death_location['timestamp'] <= intervals[2]), 'x'],
               y=death_location.loc[(death_location['timestamp'] >= intervals[1]) &
                                    (death_location['timestamp'] <= intervals[2]), 'y'],
               gridsize=125, cmap='inferno')
ax.axis('off')
ax.set_title('Interval 3')
cb = fig.colorbar(hb, ax=ax, ticks=range(0, 16))
cb.set_label('Frequency')

ax = axs[3]
hb = ax.hexbin(x=death_location.loc[(death_location['timestamp'] >= intervals[2]) &
                                    (death_location['timestamp'] <= intervals[3]), 'x'],
               y=death_location.loc[(death_location['timestamp'] >= intervals[2]) &
                                    (death_location['timestamp'] <= intervals[3]), 'y'],
               gridsize=125, cmap='inferno')
ax.axis('off')
ax.set_title('Interval 4')
cb = fig.colorbar(hb, ax=ax)
cb.set_label('Frequency')

plt.tight_layout()

plt.savefig(P4_PATH + 'misc\\death_location_time.png', bbox_inches='tight')
```

<center>![Death Location Frequency Over Time](misc\\death_location_time.png)</center>

The first interval depicts several interesting patterns. Most of the beginning of the game takes place in the middle part of each lane. This makes sense: players need to level up and earn money before they can be more adventurous. I wonder if there's more to the bottom lane having the most activity in this interval.

The fourth interval depicts something else interesting as well.

<center>![Baron Nashor location circled](misc\\time-circled.png)</center>

Compare the circled location above to the its respective location on images of other intervals: you will find that there is much more activity in that location in the fourth interval than any other. Not too surprising: that's where Baron Nashor is located, a monster typically killed in clinch games in order to gain a competitive edge. It should be noted that the activity here doesn't necessarily represent the Baron's capacity to kill players, although it certainly can; more likely, the activity highlights the Baron's appeal in the latter part of games.

# Team Statistics

```{r match_teams_import, echo=TRUE}
match_teams <- read.csv('datasets-csv\\match_teams.csv')
match_teams$towerKills <- factor(match_teams$towerKills, ordered=TRUE)
match_teams$inhibitorKills <- factor(match_teams$inhibitorKills, ordered=TRUE)
```

This dataset consists of 2000 observations of teams from 1000 matches (two teams per match). The dataset records 12 variables. The matchId field serves as an index. 

### Sanity Checks

```{r match_teams_summary}
summary(match_teams)
```

The major function of this summary is as a sanity check. That is:

* *Does every match end definitively? I.e., is there a winner and a loser?* Yes. The dataset consists of teams from 1000 matches and there are 1000 winners and losers.

Moreover, the summary provides insight into the way in which wins were achieved:

* *Does the summary read 1000 True/False for firstTower? What about for firstInhibitor? What do the answers to these questions mean?* It does for firstTower but not for firstInhibitor. What does this mean? Well, we know that at least one inhibitor must be destroyed before the towers guarding the nexus can be targeted, and these towers must be destroyed before the nexus can be targeted. So if the number of False values exceeds 1000 by 86, then at least 86 matches must have concluded in a surrender.

The summary indicates something else, which actually surprised me. From my experience, I expected that the frequency of Baron Nashor kills would be far larger than that of the dragon. This data, however, suggests the opposite, with 993 True for firstDragon and 584 True for firstBaron.

### Tower and Inhibitor Destruction Numbers

We'd expect that the number of teams who won increases as a function of the number of towers destroyed. Let's see if this is true.

```{r towerKills_winner}
ggplot(match_teams, aes(x=towerKills)) +
  stat_count() +
  xlab('Towers Destroyed') +
  ylab('Frequency') +
  ggtitle('Frequency of Losing/Winning (Top/Bottom) Teams That Destroyed N Towers') +
  facet_grid(winner ~ .)
```

Indeed, this figure generally supports our expectation. This pattern is violated around 10-11 for winning teams; but the fact that the number of teams who destroyed 11 towers is smaller than the number of teams who destroyed 10 may suggest that there isn't much of a gain from having destroyed every tower. You can probably think of many matches in which this makes sense.

On another note, don't be alarmed by the existence of teams who won without having destroyed at least 6 towers (recall that the minimal conditions for a victory without surrender is the destruction of all towers in a lane + its inhibitor's tower + both nexus towers), as this isn't necessarily an indication of faulty data. Remember that at least 86 matches ended by surrender.

Let's take a quick detour. We may not have an expectation of the relationship between towers destroyed and whether a particular monster was killed (at least I don't). So let's graph that relationship and see if it reveals anything.

```{r towerKills_monsters}
g1 <- ggplot(match_teams, aes(x=towerKills)) +
  geom_bar() +
  xlab('Towers Destroyed') +
  ylab('Frequency') +
  ggtitle('Killed At Least One Baron?') +
  facet_grid((baronKills > 0) ~ .)
g2 <- ggplot(match_teams, aes(x=towerKills)) +
  geom_bar() +
  xlab('Towers Destroyed') +
  ylab('Frequency') +
  ggtitle('Killed At Least One Dragon?') +
  facet_grid((dragonKills > 0) ~ .)
g3 <- ggplot(match_teams, aes(x=towerKills)) +
  geom_bar() +
  xlab('Towers Destroyed') +
  ylab('Frequency') +
  ggtitle('Killed At Least One Rift Herald?') +
  facet_grid((riftHeraldKills > 0) ~ .)

t <- textGrob('Frequency of Teams That Destroyed N Towers')

grid.arrange(t, g3, g1, g2, nrow=2, ncol = 2)
```

As far as the dragon and Baron Nashor are concerned, there does appear to be a slight-to-moderate trend. However, no trend appears with respect to the rift herald.

Returning to faceting by win, let's now add another variable to this investigation.

```{r towerKills_InhibitorKills}
ggplot(match_teams, aes(towerKills, inhibitorKills))+
  geom_count() + 
  xlab('Towers Destroyed') +
  ylab('Inhibitors Destroyed') +
  ggtitle('Frequency of Teams that Destroyed N Towers, M Inhibitors') +
  facet_grid(winner ~ .)
```

That inhibitors and towers destroyed have a monotonic relationship doesn't reveal anything, since the scheme of the game imposes this as a condition for victory. What is somewhat revealing, though, is the team frequency, particularly with regard to losing teams. It seems that the vast majority of losing teams either: 1) didn't destroy enough towers to be able to destroy an inhibitor or 2) destroyed enough towers but didn't destroy an inhibitor. Perhaps this speaks to the importance of a key aspect to success in many LoL matches: momentum. 

### Early Momentum

Good momentum built early in the match should better position a team for victory. In the following two graphs, we will investigate whether this true. 

```{r alluvial_1}
par(oma=c(0, 0, .5, 0))

agg <- aggregate(rep(1, nrow(match_teams)) ~ winner + firstInhibitor + firstTower + firstBlood, 
                 FUN=sum, 
                 data=match_teams[, -1])


alluvial(agg[, 1:(ncol(agg)-1)], freq=agg[, ncol(agg)], 
         col=ifelse(agg$winner == 'True', 'midnightblue', 'mediumaquamarine'),
         axis_labels=c('Winner?', 'Destroyed First Inhibitor?', 'Destroyed First Tower?', 'First Blood?'),
         alpha=0.8)
```

This diagram reveals a lot. Notably:

* First blood isn't as strong of an indicator of victory as the other two categories.
* Being first to destroy an inhibitor appears to be the strongest indicator of victory, as a vast majority of these winners destroyed the first inhibitor. The proportion may even be larger than what's depicted, since 86 matches ended before an inhibitor was even destroyed.

We can consider the number of towers destroyed with these variables as well.

```{r alluvial_2}
par(oma=c(0, 3, .5, 0))

agg <- aggregate(rep(1, nrow(match_teams)) ~  firstTower + towerKills + winner, 
                 FUN=sum, 
                 data=match_teams[, -1])


alluvial(agg[, 1:(ncol(agg)-1)], freq=agg[, ncol(agg)], 
         col=ifelse(agg$firstTower == 'True', 'midnightblue', 'mediumaquamarine'),
         axis_labels=c('Destroyed First Tower?', 'Number of Towers Destroyed', 'Winner'),
         alpha=0.8)
```

This diagram shows that having destroyed the first tower is a fairly strong indicator of destroying more towers.

# Champion Popularity

```{r champ_popularity_import, echo=TRUE}
champ_popularity <- read.csv('datasets-csv\\champ_popularity.csv')
```

This dataset consists of 128 observations of champions. The dataset records the frequency of champion choice by tier for 1000 matches. 

We won't spend much time in this section. Our primary interest here is to identify the most/least popular champions chosen by players of each tier.

```{python champ_popularity, include=FALSE}
import matplotlib.pyplot as plt
import pandas as pd

P4_PATH = 'Q:\\Program Files\\Programming Applications\\Projects\\Udacity\\Data Analysis Nanodegree\\P4\\'

champ_popularity = pd.read_csv(P4_PATH + 'datasets-csv\\champ_popularity.csv')

# Creates indices for the top/bottom five in each tier
sorted_index = champ_popularity.iloc[:, 1:].sum(axis=1).sort_values().index

champ_popularity.columns = ['champion name', 'unranked', 'bronze', 'silver', 'gold',
                            'platinum', 'diamond', 'master', 'challenger', 'total']

cols = [col for col in champ_popularity.columns if col != 'champion name']
champ_popularity[cols] = champ_popularity[cols].apply(lambda series: (series/series.sum())*100)

top_5 = {}
bottom_5 = {}
for col in cols:
    top_5[col] = champ_popularity[col].sort_values(ascending=False)[:5].index
    bottom_5[col] = champ_popularity[col].sort_values(ascending=True)[:5].index

colors = ['olive', 'darkgoldenrod', 'silver', 'gold', 'gainsboro', 'white', 'b', 'r', 'black']

# Most popular
fig, axs = plt.subplots(nrows=len(cols), sharex=True, figsize=(7, 9))

for i, col in zip(range(len(cols)), cols):
    champ_popularity.iloc[top_5[col], :].plot(x='champion name', y=col, 
                                            kind='barh',
                                            ax=axs[i],
                                            title='5 Most Popular Champions: ' + col.upper(),
                                            color=colors[i], 
                                            legend=False)
    axs[i].set_ylabel('')
    axs[i].tick_params(axis='y', which='major', labelsize=7)

plt.xlabel('Percent times chosen by players in tier')
plt.tight_layout()

plt.savefig(P4_PATH + 'misc\\most_pop_champ.png', dpi=fig.dpi, bbox_inches='tight')

# Least popular
fig, axs = plt.subplots(nrows=len(cols), sharex=True, figsize=(7, 9))

for i, col in zip(range(len(cols)), cols):
    champ_popularity.iloc[bottom_5[col], :].plot(x='champion name', y=col, 
                                            kind='barh',
                                            ax=axs[i],
                                            title='5 Least Popular Champions: ' + col.upper(),
                                            color=colors[i], 
                                            legend=False)
    axs[i].set_ylabel('')
    axs[i].tick_params(axis='y', which='major', labelsize=7)
    
plt.xlabel('Percent times chosen by players in tier')
plt.tight_layout()

plt.savefig(P4_PATH + 'misc\\least_pop_champ.png', dpi=fig.dpi, bbox_inches='tight')
```

<center>![](misc\\most_pop_champ.png)</center>

Miss Fortune is quite popular, appearing in 6 out of the 8 tiers and being the most popular champion in total.

<center>![](misc\\least_pop_champ.png)</center>

Yorick is quite unpopular, appearing in 7 out of the 8 tiers adn being the least popular champion in total.

# First Blood Times

```{r firstBlood_times_import, echo=TRUE}
# the matchId column serves as an index
firstBlood_times <- read.csv('datasets-csv\\firstBlood_times.csv')
```

This dataset consists of 1000 observations of matches. The dataset records the time at which the match's first blood occurred.

Our objective with this dataset is to come up with a confidence interval for some measure of central tendency of the distribution of the first blood times. Thus we should first plot the times in order to see: 1) what measure of central tendency will work best with our data and 2) if rudimentary methods for constructing confidence intervals can be used (i.e. is the distribution of the data reasonably symmetric?)

```{r firstBlood_density}
ggplot(firstBlood_times, aes(x=firstBlood_timestamp)) + 
  ggtitle('Density Estimate for First Blood Times') +
  xlab('Time (sec)') +
  scale_x_continuous(limits = c(0, 600)) +
  stat_bin(aes(y=..density..), color='grey', bins=30) + 
  geom_density(fill=NA, colour="black")
```

The graph may, at first glance, appear normal, albeit a bit skewed. What worries me is the second hump to the left of the first. Because of that hump, I don't feel that we should construct a confidence interval using rudimentary methods, nor do I think we should use the mean as the measure of central tendency. Instead, we should use the median.

### Bootstrapping for Median's Confidence Interval

```{r bootstrap}
nboot <- 3000
alpha <- 0.05
sample_size <- 1000

boot_median <- function(x, i) {
  quantile(x[i], probs=.5)
}

theta_boot_median <- boot(firstBlood_times$firstBlood_timestamp,
                          boot_median,
                          nboot)
boot.ci(theta_boot_median, conf=1-alpha)
```

We typically regard as most favorable the bias-corrected and accelerated (BCa) boostrap confidence interval; it will be our chosen confidence interval here.

# Level Up Times

This dataset consists of 146,096 observations of players for 1000 matches. The dataset records 6 variables. The matchId and participantId fields serve as indices. 

```{r levelUp_times_import, echo=TRUE}
levelUp_times <- read.csv('datasets-csv\\levelUp_times.csv')
levelUp_times[, 'highestAchievedSeasonTier'] <- 
  factor(levelUp_times$highestAchievedSeasonTier,
         levels=c('UNRANKED', 'BRONZE' , 'SILVER', 'GOLD',
                  'PLATINUM', 'DIAMOND', 'MASTER', 'CHALLENGER'),
         ordered=TRUE)
levelUp_times <- data.table(levelUp_times)
```

```{r levelUp_times_summary}
levelUp_times %>% group_by(lvlAchieved) %>% 
  summarise(first_quartile_in_sec=quantile(timestamp, prob=.25),
            median_time_in_sec=median(timestamp),
            third_quartile_in_sec=quantile(timestamp, prob=.75),
            n=n()) %>%
  tail
```

It may not be surprising that the median times increase as the level achieved increases. However, this is not always true. For levels after 19, the strictly monotone relationship deteriorates. We will see this in the figure below.

Also shown below: the distribution of levels 20 and above are shifted to the left quite a bit in comparison to the levels just below 20.

```{r levelUp_times_density}
ggplot(levelUp_times[lvlAchieved >= 17][lvlAchieved != 23], aes(factor(lvlAchieved), timestamp/60)) +
  stat_boxplot(outlier.colour='red', outlier.shape = 1) +
  xlab('Level Achieved') +
  ylab('Time (min)') +
  ggtitle('Density Estimates for Times At Which Level N Was Achieved') +
  coord_flip()
```

We should be a bit skeptical of these values for levels 20 and above. Why? Remember from the summary report that the size of each group is very small. So perhaps for those groups our data isn't a good representation of the population. 

All that considered, let's now look at a frequency plot for all levels. We will divide the plots in two so that they are easier to read.

```{r levelUp_times_freq_lower}
ggplot(levelUp_times[lvlAchieved <= 12], aes(timestamp, colour=factor(lvlAchieved))) +
  geom_freqpoly(binwidth=40) +
  xlab('Time (sec)') +
  ylab('Frequency') +
  ggtitle('Frequency of Times At Which Level N Was Achieved') +
  scale_colour_discrete(name="Level Achieved")
```

Let's first take care of the, what may at first appear to be, strange pattern between level 2 and 3. You probably expect that frequency will becomes less concentrated as a function of increasing level; for, as one levels up, it becomes harder to do so, and higher performing players will outpace their counterparts. Thus level 3's frequency shouldn't be much more concentrated than level 2. From my experience, I suspect that this strange pattern is a result of players being away from the keyboard (AFK) at the beginning of the game&mdash;something which happens quite often. But this is not certain. In any case, for all other levels, the frequency does become less concentrated as a function of increasing level. See the graph above and the graph below to confirm.

```{r levelUp_times_freq_mid-upper}
ggplot(levelUp_times[lvlAchieved > 12], aes(timestamp, colour=factor(lvlAchieved))) +
  geom_freqpoly(binwidth=40) +
  xlab('Time (sec)') +
  ylab('Frequency') +
  ggtitle('Frequency of Times At Which Level N Was Achieved') +
  scale_colour_discrete(name="Level Achieved")
```

Now, let's compare the median times to achieve a certain level.

```{r levelUp_median}
ggplot(levelUp_times, aes(lvlAchieved, timestamp/60, colour=highestAchievedSeasonTier)) +
  geom_step(stat='summary', fun.y=median) +
  xlab('Level Achieved') +
  ylab('Time (min)') +
  ggtitle('Median Time to Achieve Level N by Tier') +
  scale_colour_brewer(name='Tier', type = "seq", palette = "Oranges") +
  theme_dark()
```

The median times do appear to disperse as a function of increasing level, although the details of the dispersion may not be clear.

```{r levelUp_median_truncated}
ggplot(levelUp_times[lvlAchieved >= 10][lvlAchieved <= 18],
       aes(lvlAchieved, timestamp/60, colour=highestAchievedSeasonTier)) +
  geom_step(stat='summary', fun.y=median) +
  xlab('Level Achieved') +
  ylab('Time (min)') +
  ggtitle('Median Time to Achieve Level N by Tier') +
  scale_colour_brewer(name='Tier', type = "seq", palette = "Oranges") +
  theme_dark()
```

Indeed, this chart clairifies the dispersion. As expected, the median time to achieve level n generally appears to decrease as tier level increases&mdash;i.e., median times for the bronze tier become higher than diamond as level increases. This is not true for the unranked tier, whose median times float between those of silver and gold. But since the unranked tier could contain players who might belong to any tier, this isn't too surprising.

# Kills/Deaths/Assits

```{r kda_performance_import, echo=TRUE}
kda_performance <- read.csv('datasets-csv\\kda_performance.csv')
kda_performance[, 'highestAchievedSeasonTier'] <- 
  factor(kda_performance$highestAchievedSeasonTier,
         levels=c('UNRANKED', 'BRONZE' , 'SILVER', 'GOLD',
                  'PLATINUM', 'DIAMOND', 'MASTER', 'CHALLENGER'),
         ordered=TRUE)
```

This dataset consists of 10,000 observations of players for 1000 matches. The dataset records 5 variables. The summonerId field serves as an index.

```{r kda_summary}
kda_performance %>% group_by(highestAchievedSeasonTier) %>%
  summarise(mean_performance=mean(avg.performance),
            median_performance=median(avg.performance),
            n=n())
```

It is important to discuss how 'performance' was measured here. I wanted a metric that: 1) was normalized and 2) would take into account kills, assists, and deaths so that all three could be easily depicted in one graph. 

Now, what immediately came to mind was a metric that I use for sports data. This metric works as follows: for $w$ wins, $t$ ties, and $l$ losses, the performance measure $p$ is defined as $p(w, t, l) = \frac{w - l}{w + t + l}$. The issue is that the way in which this metric assigns values to wins, ties, and losses makes intuitive sense for sports data but just doesn't translate well to LoL K/D/A data. A kill is intuitively +1, a death -1, but what's intuitive about assigning 0 to an assist? In fact, pretty much any value assigned to assists seems somewhat arbitrary. 

In the end, I decided, based on my experience in the game, that +1 should be assigned to assists. So the performance measure here is the following: for $k$ kills, $a$ assists, and $d$ deaths, the performance measure $p$ is defined as $p=\frac{k + a - d}{k + a + d}$. In deciding this, I thought about all those moments when I depleted an enemy champion's HP to nearly, but not quite, 0; the enemy managed to escape me but not another player, who entered the scene and made an easy picking. Why should the assist be valued less than the kill in this scenario? It shouldn't.

Now that the performance measure has been explained, let's get to interpreting the statistics. Since tiers are, in general, paired together in match making, we should expect that the mean and median performances for each would be roughly the same. Between bronze and diamond, this does appear to be true. Master and Challenger tiers deviate from this pattern, but that's to be expected. After all, the challengers are literally the best LoL players in the world. 

But which measure of central tendency is the most accurate? Considering that the performances are quite skewed for each (see graph below), we should go with the median.

```{r kda_dist}
g1 <- ggplot(kda_performance, aes(highestAchievedSeasonTier, avg.performance)) +
  geom_jitter(alpha=.03) +
  xlab('Tier') +
  ylab('Performance') +
  ggtitle('Jitter Plot by Tier') +
  coord_flip()

g2 <- ggplot(kda_performance, aes(highestAchievedSeasonTier, avg.performance)) +
  geom_violin() +
  xlab('Tier') +
  ylab('Performance') +
  ggtitle('Boxplot by Tier') +
  coord_flip()

grid.arrange(g1, g2, nrow=1, ncol = 2)
```

------

# Final Plots and Summary

### Plot and Description One

<center>![](misc\\death_location_time.png)</center>

The first interval depicts several interesting patterns. Most of the beginning of the game takes place in the middle part of each lane. This makes sense: players need to level up and earn money before they can be more adventurous. I wonder if there's more to the bottom lane having the most activity in this interval.

The fourth interval depicts something else interesting as well. 

<center>![](misc\\time-circled.png)</center>

Compare the circled location above to the its respective location on images of other intervals: you will find that there is much more activity in that location in the fourth interval than any other. Not too surprising: that's where Baron Nashor is located, a monster typically killed in clinch games in order to gain a competitive edge. It should be noted that the activity here doesn't necessarily represent the Baron's capacity to kill players, although it certainly can; more likely, the activity highlights the Baron's appeal in the latter part of games.

### Plot Two

```{r fp_alluvial_1}
par(oma=c(0, 0, .5, 0))

agg <- aggregate(rep(1, nrow(match_teams)) ~ winner + firstInhibitor + firstTower + firstBlood, 
                 FUN=sum, 
                 data=match_teams[, -1])


alluvial(agg[, 1:(ncol(agg)-1)], freq=agg[, ncol(agg)], 
         col=ifelse(agg$winner == 'True', 'midnightblue', 'mediumaquamarine'),
         axis_labels=c('Winner?', 'Destroyed First Inhibitor?', 'Destroyed First Tower?', 'First Blood?'),
         alpha=0.8)
```

### Description Two

This diagram reveals a lot. Notably: 1) First blood isn't as strong of an indicator of victory as the other two categories. 2) Being first to destroy an inhibitor appears to be the strongest indicator of victory, as a vast majority of these winners destroyed the first inhibitor. The proportion may even be larger than what's depicted, since 86 matches ended before an inhibitor was even destroyed.

### Plot Three

```{r fp_levelUp_median}
ggplot(levelUp_times, aes(lvlAchieved, timestamp/60, colour=highestAchievedSeasonTier)) +
  geom_step(stat='summary', fun.y=median) +
  xlab('Level Achieved') +
  ylab('Time (min)') +
  ggtitle('Median Time to Achieve Level N by Tier') +
  scale_colour_brewer(name='Tier', type = "seq", palette = "Oranges") +
  theme_dark()
```

### Description Three

The median time to achieve level n generally appears to decrease as tier level increases&mdash;i.e., median times for the bronze tier become higher than diamond as level increases. This is not true for the unranked tier, whose median times float between those of silver and gold. But since the unranked tier could contain players who might belong to any tier, this isn't too surprising.

We should be a bit skeptical of the values for levels past 20. Why? Remember from the summary report that the size of each group is very small. So perhaps for those groups our data isn't a good representation of the population. 

------

# Reflection

The analysis was, by and large, a success in my opinion&mdash;to such an extent that I would like to use these datasets for future analyses (and perhaps develop them even further).

Nonetheless, there were a few areas with which I did struggle&mdash;notably, the peformance measure. Even though it is a sufficient measure for the moment, I would like to have a measure that feels as intuitive as the performance measures for other sports.

### Future Work

Here are several exploratory questions for future work:

1. Can we determine a reason for the high death activity in the bottom lane during the early stages of the game?
2. Can we determine a reason for the relationship uncovered in this analysis between monster kills and towers destroyed?
3. Does the relative kill it takes to successfully play a champion correlate with a champion's tier popularity? I.e., are harder champions favored by players in a higher tier?

Personally, I would really like to study ward placement patterns. But from what I've read in the forums, Riot doesn't disclose this information because players can use it to study the actions of other players (don't sports teams do this?). Maybe in the future they can release ward placement datasets with redacted summonerId entries? 

Other interesting directions to investigate revolve around constructing models to predict winning teams.
